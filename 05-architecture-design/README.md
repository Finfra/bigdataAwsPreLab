# 5. 아키텍처 설계 및 검토

* 핵심 내용 : AWS 기반 분산 아키텍처 설계, 리스크 분석
* 주요 산출물 : 아키텍처 다이어그램, 리스크 분석

---


## 개요

이번 장에서는 우리가 구축할 빅데이터 파이프라인의 전체적인 아키텍처를 설계합니다. 각 컴포넌트의 역할과 데이터의 흐름을 명확히 정의하고, 클라우드 환경의 이점을 살린 확장 가능하고 안정적인 아키텍처를 구상하는 방법을 실습합니다.

## 주요 실습 내용

* **데이터 파이프라인의 단계별 이해 (수집, 저장, 처리, 분석, 시각화)**
* **AWS 서비스와 오픈소스 기술을 결합한 아키텍처 설계**
* **데이터 흐름도(Data Flow Diagram) 작성**
* **아키텍처 설계 시 고려사항 (확장성, 안정성, 비용, 보안)**

## Pre-Lab 아키텍처 다이어그램

아래는 이번 Pre-Lab에서 구축할 빅데이터 파이프라인의 전체 아키텍처입니다.

```plaintext
┌──────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                  AWS Cloud (ap-northeast-2)                                      │
│                                                                                                  │
│ ┌───────────────────────────┐         ┌───────────────────────────────────────────────────────┐  │
│ │     Data Source           │         │                    VPC (10.0.0.0/16)                  │  │
│ │       (On-prem)           │────────▶│                                                       │  │
│ │ ┌───────────────────────┐ │         │ ┌───────────────────┐    ┌──────────────────────────┐ │  │
│ │ │ Web Server Logs, DB   │ │         │ │   Public Subnet   │    │      Private Subnet      │ │  │
│ │ └───────────────────────┘ │         │ │                   │    │                          │ │  │
│ └───────────────────────────┘         │ │ ┌───────────────┐ │    │ ┌──────────────────────┐ │ │  │
│                                       │ │ │ Console Server│ │    │ │ s1 (NN)              │ │ │  │
│                                       │ │ │(Ansible,      │ │    │ │ (HDFS, YARN, Spark)  │ │ │  │
│                                       │ │ │ Bastion Host) │ │    │ └──────────────────────┘ │ │  │
│                                       │ │ └───────────────┘ │    │                          │ │  │
│                                       │ │                   │    │ ┌──────────────────────┐ │ │  │
│                                       │ │                   │    │ │ s2 (DN)              │ │ │  │
│                                       │ │                   │    │ │ (HDFS, YARN, Spark)  │ │ │  │
│                                       │ │                   │    │ └──────────────────────┘ │ │  │
│                                       │ │                   │    │                          │ │  │
│                                       │ │                   │    │ ┌──────────────────────┐ │ │  │
│                                       │ │                   │    │ │ s3 (DN)              │ │ │  │
│                                       │ │                   │    │ │ (HDFS, YARN, Spark)  │ │ │  │
│                                       │ │                   │    │ └──────────────────────┘ │ │  │
│                                       │ └───────────────────┘    └──────────────────────────┘ │  │
│                                       └───────────────────────────────────────────────────────┘  │
│                                                                                                  │
└──────────────────────────────────────────────────────────────────────────────────────────────────┘

```

## 컴포넌트별 역할

* **Data Source:** 데이터가 생성되는 원천입니다. 웹 서버의 로그, 운영 데이터베이스의 데이터, IoT 장치의 센서 데이터 등 다양한 형태가 될 수 있습니다.
* **Console Server:**
    * **Bastion Host:** 외부에서 Private Subnet에 있는 서버들(s1, s2, s3)에 안전하게 접속하기 위한 경유 서버 역할을 합니다.
    * **Ansible Control Node:** Ansible을 실행하여 s1, s2, s3 서버의 구성을 자동화하는 중앙 제어 노드입니다.
* **Hadoop/Spark Cluster (s1, s2, s3):**
    * **HDFS (Hadoop Distributed File System):** 대용량 데이터를 분산하여 저장하는 파일 시스템입니다. s1이 NameNode, s2, s3가 DataNode 역할을 수행하도록 구성할 수 있습니다.
    * **YARN (Yet Another Resource Negotiator):** 클러스터의 리소스를 관리하고 작업(Job)을 스케줄링하는 역할을 합니다.
    * **Spark:** HDFS에 저장된 데이터를 병렬로 처리하는 인메모리 기반의 고속 데이터 처리 프레임워크입니다.
* **VPC (Virtual Private Cloud):** AWS 계정 내에 논리적으로 격리된 가상 네트워크 환경을 제공합니다. Public Subnet과 Private Subnet으로 나누어 보안을 강화합니다.

## 데이터 흐름

1. **데이터 수집:** 외부 데이터 소스에서 생성된 데이터는 Kafka와 같은 메시징 큐를 통해 수집되거나, AWS의 Data Migration Service(DMS), Kinesis 등을 통해 AWS 환경으로 들어옵니다. (이번 Pre-Lab에서는 s1 서버에 직접 데이터를 업로드하는 방식을 사용할 수 있습니다.)
2. **데이터 저장:** 수집된 원본 데이터는 HDFS에 저장됩니다.
3. **데이터 처리:** Spark 애플리케이션을 통해 HDFS에 저장된 데이터를 읽어와 필요한 형태로 변환하고 분석합니다.
4. **데이터 분석 및 시각화:** 처리된 결과는 분석가나 다른 시스템에서 사용할 수 있도록 정제된 형태로 다시 HDFS나 다른 데이터베이스에 저장될 수 있으며, BI 툴이나 Grafana와 같은 시각화 도구를 통해 모니터링하고 분석합니다.

## 다음 챕터

다음 장에서는 설계한 아키텍처에 따라, Ansible을 사용하여 s1, s2, s3 서버에 Hadoop과 Spark 클러스터를 실제로 구축하고 설정하는 구체적인 방법을 실습합니다.
